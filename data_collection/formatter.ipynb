{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "from sentiment_analysis.makeDataset import *\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>am_pm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>Morning Bid: Dollar surges after central bank ...</td>\n",
       "      <td>A look at the day ahead in U.S. and global mar...</td>\n",
       "      <td>2024-03-22</td>\n",
       "      <td>06:08</td>\n",
       "      <td>AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>Evercore says Apple sell-off is overdone, sees...</td>\n",
       "      <td>Apple (NASDAQ:AAPL) stock remains one of the v...</td>\n",
       "      <td>2024-03-11</td>\n",
       "      <td>16:54</td>\n",
       "      <td>PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>US House passes bill to force ByteDance to div...</td>\n",
       "      <td>By David ShepardsonWASHINGTON (Reuters) -The U...</td>\n",
       "      <td>2024-03-13</td>\n",
       "      <td>06:01</td>\n",
       "      <td>AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>APPLE ALERT: Bragar Eagel &amp; Squire, P.C. is In...</td>\n",
       "      <td>NEW YORK, March 22, 2024 (GLOBE NEWSWIRE) -- B...</td>\n",
       "      <td>2024-03-22</td>\n",
       "      <td>21:12</td>\n",
       "      <td>PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>Apple have to find a way to settle potential D...</td>\n",
       "      <td>Following reports that the U.S. Department of ...</td>\n",
       "      <td>2024-03-21</td>\n",
       "      <td>09:04</td>\n",
       "      <td>AM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  stock                                              title  \\\n",
       "0  AAPL  Morning Bid: Dollar surges after central bank ...   \n",
       "1  AAPL  Evercore says Apple sell-off is overdone, sees...   \n",
       "2  AAPL  US House passes bill to force ByteDance to div...   \n",
       "3  AAPL  APPLE ALERT: Bragar Eagel & Squire, P.C. is In...   \n",
       "4  AAPL  Apple have to find a way to settle potential D...   \n",
       "\n",
       "                                                text        date   time am_pm  \n",
       "0  A look at the day ahead in U.S. and global mar...  2024-03-22  06:08    AM  \n",
       "1  Apple (NASDAQ:AAPL) stock remains one of the v...  2024-03-11  16:54    PM  \n",
       "2  By David ShepardsonWASHINGTON (Reuters) -The U...  2024-03-13  06:01    AM  \n",
       "3  NEW YORK, March 22, 2024 (GLOBE NEWSWIRE) -- B...  2024-03-22  21:12    PM  \n",
       "4  Following reports that the U.S. Department of ...  2024-03-21  09:04    AM  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../datasets/stock_news.csv')\n",
    "# drop rows with stock == 'TMTG'\n",
    "df = df[df['stock'] != 'TMTG']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max: 2024-03-19 - min: 2020-11-04\n",
      "['2024-03-22' '2024-03-21' '2024-03-28' '2024-03-25' '2024-03-29'\n",
      " '2024-03-19' '2024-03-26' '2024-03-20' '2024-03-27' '2024-03-24'\n",
      " '2024-03-23']\n",
      "['AAPL' 'AMC' 'AMD' 'AMZN' 'BA' 'BABA' 'BAC' 'CCL' 'COIN' 'DIS' 'GE'\n",
      " 'GOOGL' 'INTC' 'LCID' 'MARA' 'META' 'MSFT' 'MSTR' 'NFLX' 'NIO' 'NKLA'\n",
      " 'NVDA' 'PFE' 'PLTR' 'PYPL' 'SMCI' 'SNOW' 'TLRY' 'TSLA']\n"
     ]
    }
   ],
   "source": [
    "min_dates = df.groupby('stock')['date'].min()\n",
    "print(\"max:\", max(min_dates), \"- min:\", min(min_dates))\n",
    "news_df = df[df['date'] >= max(min_dates)]\n",
    "unique_dates = news_df['date'].unique()\n",
    "unique_stocks = news_df['stock'].unique()\n",
    "print(unique_dates)\n",
    "print(unique_stocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('yiyanghkust/finbert-tone', do_lower_case=True)\n",
    "model = BertForSequenceClassification.from_pretrained(\"../sentiment_analysis/saved_models/finbert_finetuned\")\n",
    "device = torch.device('cuda')\n",
    "DEVICE = torch.device('cuda')\n",
    "model = model.to(device)\n",
    "\n",
    "batch_size = 16\n",
    "mapper = {'negative': 0, 'neutral': 1, 'positive': 2}\n",
    "reverse_mappers = {0: 'negative', 1: 'neutral', 2: 'positive'}\n",
    "\n",
    "date_stock_dict = {}\n",
    "for new_date in unique_dates:\n",
    "    temp_df = news_df[news_df['date'] == new_date]\n",
    "    stock_dict = {}\n",
    "    for stock_name in unique_stocks:\n",
    "        if stock_name in temp_df['stock'].values:\n",
    "            stocks_in_one_day_title_x = temp_df[temp_df['stock'] == stock_name]['title']\n",
    "            stocks_in_one_day_text_x = temp_df[temp_df['stock'] == stock_name]['text']\n",
    "            stock_dict[stock_name] = (stocks_in_one_day_title_x, stocks_in_one_day_text_x)\n",
    "    date_stock_dict[new_date] = stock_dict\n",
    "new_title_list = []\n",
    "new_text_list = []\n",
    "for date, stock_dict in date_stock_dict.items():\n",
    "    for stock_name, (title_x, text_x) in stock_dict.items():\n",
    "        new_title_list.extend(list(title_x))\n",
    "        new_text_list.extend((text_x))\n",
    "x = np.array(new_title_list)\n",
    "x2 = np.array(new_text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "953"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = CustomDataset(x, None, tokenizer, max_len=32)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_dataset2 = CustomDataset(x2, None, tokenizer, max_len=512)\n",
    "test_loader2 = DataLoader(test_dataset2, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "model.eval()\n",
    "title_predictions = []\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        _, predicted = torch.max(outputs.logits, 1)\n",
    "        temp_list = [int(each) for each in predicted.cpu().numpy()]\n",
    "        for each in temp_list:\n",
    "            title_predictions.append(reverse_mappers[each])\n",
    "\n",
    "model.eval()\n",
    "text_predictions = []\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader2:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        _, predicted = torch.max(outputs.logits, 1)\n",
    "        temp_list = [int(each) for each in predicted.cpu().numpy()]\n",
    "        for each in temp_list:\n",
    "            text_predictions.append(reverse_mappers[each])\n",
    "torch.cuda.empty_cache()\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the model\n",
    "model2 = DistilBertForSequenceClassification.from_pretrained(\"../sentiment_analysis/saved_models/flair_model\")\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "# Predict sentiment for x\n",
    "x_encodings = tokenizer(list(x), truncation=True, padding=True, max_length=32)\n",
    "x_dataset = TensorDataset(\n",
    "    torch.tensor(x_encodings['input_ids']),\n",
    "    torch.tensor(x_encodings['attention_mask'])\n",
    ")\n",
    "x_dataloader = DataLoader(x_dataset, batch_size=batch_size)\n",
    "x_predictions = []\n",
    "model2.eval()\n",
    "for batch in x_dataloader:\n",
    "    input_ids, attention_mask = batch\n",
    "    input_ids = input_ids.to(DEVICE)\n",
    "    attention_mask = attention_mask.to(DEVICE)\n",
    "    model2 = model2.to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        outputs = model2(input_ids, attention_mask=attention_mask)\n",
    "    predicted_labels = torch.argmax(outputs.logits, dim=1)\n",
    "    x_predictions.extend(predicted_labels.tolist())\n",
    "\n",
    "# Predict sentiment for x2\n",
    "x2_encodings = tokenizer(list(x2), truncation=True, padding=True, max_length=512)\n",
    "x2_dataset = TensorDataset(\n",
    "    torch.tensor(x2_encodings['input_ids']),\n",
    "    torch.tensor(x2_encodings['attention_mask'])\n",
    ")\n",
    "x2_dataloader = DataLoader(x2_dataset, batch_size=batch_size)\n",
    "x2_predictions = []\n",
    "model2.eval()\n",
    "for batch in x2_dataloader:\n",
    "    input_ids, attention_mask = batch\n",
    "    input_ids = input_ids.to(DEVICE)\n",
    "    attention_mask = attention_mask.to(DEVICE)\n",
    "    model2 = model2.to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        outputs = model2(input_ids, attention_mask=attention_mask)\n",
    "    predicted_labels = torch.argmax(outputs.logits, dim=1)\n",
    "    x2_predictions.extend(predicted_labels.tolist())\n",
    "\n",
    "# Map sentiment index to labels\n",
    "sentiment_labels = {0: 'negative', 1: 'neutral', 2: 'positive'}\n",
    "\n",
    "# Print the predictions with real labels\n",
    "title_sentiment_list = []\n",
    "for sentiment in x_predictions:\n",
    "    title_sentiment_list.append(sentiment_labels[sentiment])\n",
    "\n",
    "text_sentiment_list = []\n",
    "for sentiment in x2_predictions:\n",
    "    text_sentiment_list.append(sentiment_labels[sentiment])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_majority_vote(vote_dict):\n",
    "    new_dict = {}\n",
    "    for stock_name, votes in vote_dict.items():\n",
    "        negative = votes['negative']\n",
    "        positive = votes['positive']\n",
    "        if negative == positive and negative == 0:\n",
    "            max_voter = 0\n",
    "        else:\n",
    "            if negative > positive:\n",
    "                max_voter = -1\n",
    "            else:\n",
    "                max_voter = 1\n",
    "        new_dict[stock_name] = max_voter\n",
    "    return new_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'2024-03-22': {'AAPL': -1, 'AMZN': 0, 'BABA': 0, 'BAC': 1, 'CCL': -1, 'COIN': 1, 'GOOGL': 1, 'META': 1, 'MSFT': -1, 'MSTR': -1, 'NIO': 1, 'NVDA': 1, 'PFE': 1, 'TSLA': 1}, '2024-03-21': {'AAPL': 1, 'AMZN': 1, 'BA': 1, 'BABA': 0, 'BAC': -1, 'COIN': 1, 'DIS': 1, 'GOOGL': 1, 'INTC': 1, 'META': -1, 'MSFT': 1, 'MSTR': 1, 'NKLA': -1, 'NVDA': -1, 'SMCI': 0, 'SNOW': 0, 'TSLA': 0}, '2024-03-28': {'AAPL': 1, 'AMC': -1, 'AMZN': -1, 'BA': 0, 'BABA': 0, 'BAC': 0, 'CCL': 0, 'COIN': -1, 'DIS': 1, 'GE': 1, 'GOOGL': 1, 'INTC': -1, 'META': 1, 'MSFT': 1, 'MSTR': -1, 'NVDA': 1, 'PLTR': 1, 'PYPL': 1, 'SMCI': 1, 'SNOW': -1, 'TLRY': -1, 'TSLA': -1}, '2024-03-25': {'AAPL': -1, 'AMD': 1, 'AMZN': 1, 'BA': -1, 'BAC': 1, 'CCL': 1, 'COIN': 1, 'DIS': 1, 'GOOGL': -1, 'INTC': -1, 'LCID': -1, 'MARA': 1, 'META': 0, 'MSFT': -1, 'MSTR': 0, 'NFLX': -1, 'NIO': 0, 'NVDA': -1, 'PFE': 1, 'SMCI': 1, 'SNOW': -1, 'TSLA': -1}, '2024-03-29': {'AAPL': 1, 'AMZN': 0, 'BA': -1, 'COIN': 0, 'META': -1, 'MSFT': 0, 'MSTR': -1, 'NVDA': 1, 'PLTR': 1, 'SNOW': -1, 'TSLA': -1}, '2024-03-19': {'AAPL': 1, 'AMD': -1, 'AMZN': 1, 'BA': 1, 'BABA': -1, 'BAC': 0, 'CCL': -1, 'COIN': -1, 'DIS': -1, 'GOOGL': 1, 'INTC': 0, 'META': -1, 'MSFT': -1, 'MSTR': -1, 'NFLX': 1, 'NVDA': 1, 'PFE': 1, 'PLTR': -1, 'SMCI': -1, 'SNOW': -1, 'TSLA': -1}, '2024-03-26': {'AAPL': -1, 'AMD': -1, 'AMZN': -1, 'BA': 1, 'BABA': 1, 'BAC': 1, 'CCL': -1, 'COIN': -1, 'DIS': -1, 'GOOGL': -1, 'INTC': 0, 'LCID': -1, 'META': -1, 'MSFT': 1, 'MSTR': -1, 'NFLX': -1, 'NVDA': -1, 'PFE': -1, 'SMCI': 0, 'TSLA': -1}, '2024-03-20': {'AAPL': -1, 'AMD': -1, 'AMZN': 1, 'BA': -1, 'CCL': -1, 'COIN': -1, 'DIS': -1, 'GOOGL': 0, 'INTC': -1, 'MARA': -1, 'META': 1, 'MSFT': 1, 'MSTR': -1, 'NFLX': -1, 'NVDA': -1, 'PFE': 0, 'SMCI': 1, 'SNOW': 1, 'TSLA': 1}, '2024-03-27': {'AAPL': 1, 'AMZN': -1, 'BA': -1, 'BABA': -1, 'BAC': 0, 'CCL': 1, 'COIN': 1, 'DIS': 1, 'GE': 1, 'GOOGL': 0, 'INTC': -1, 'META': 1, 'MSFT': 1, 'MSTR': 1, 'NFLX': 0, 'NIO': 0, 'NVDA': -1, 'PLTR': 1, 'SNOW': -1, 'TSLA': 1}, '2024-03-24': {'AAPL': 1, 'AMD': 1, 'AMZN': 1, 'BA': 0, 'GOOGL': 0, 'INTC': -1, 'META': 1, 'MSFT': -1, 'NVDA': 1, 'SNOW': -1, 'TSLA': 1}, '2024-03-23': {'AAPL': 1, 'DIS': 1, 'GOOGL': 1}}\n"
     ]
    }
   ],
   "source": [
    "final_dict = {}\n",
    "for i, (date, stock_dict) in enumerate(date_stock_dict.items()):\n",
    "    sentiment_votes = {'positive': 0, 'neutral': 0, 'negative': 0}\n",
    "    temp_dict = {}\n",
    "    for j, (stock_name, (title_x, text_x)) in enumerate(stock_dict.items()):\n",
    "        finbert_title_sentiment = title_predictions[i * len(unique_dates) + j]\n",
    "        finbert_text_sentiment = text_predictions[i * len(unique_dates) + j]\n",
    "        flair_title_sentiment = title_sentiment_list[i * len(unique_dates) + j]\n",
    "        flair_text_sentiment = text_sentiment_list[i * len(unique_dates) + j]\n",
    "        if stock_name not in temp_dict:\n",
    "            temp_dict[stock_name] = {'positive': 0, 'neutral': 0, 'negative': 0}\n",
    "        temp_dict[stock_name][finbert_title_sentiment] += 1\n",
    "        temp_dict[stock_name][finbert_text_sentiment] += 1\n",
    "        temp_dict[stock_name][flair_title_sentiment] += 1\n",
    "        temp_dict[stock_name][flair_text_sentiment] += 1\n",
    "    votes_dict = get_majority_vote(temp_dict)\n",
    "    final_dict[date] = votes_dict\n",
    "print(final_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.DataFrame(final_dict)\n",
    "final_df2 = final_df.fillna(0)\n",
    "final_df2.to_csv('../datasets/final_sentiment.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
