{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import json\n",
    "import utils as utils\n",
    "from datetime import datetime as dt\n",
    "from newspaper import Article\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>stock</th>\n",
       "      <th>link</th>\n",
       "      <th>ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tesla Inc</td>\n",
       "      <td>Tesla</td>\n",
       "      <td>https://www.investing.com/equities/tesla-motors</td>\n",
       "      <td>TSLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Palantir Technologies Inc</td>\n",
       "      <td>Palantir</td>\n",
       "      <td>https://www.investing.com/equities/palantir-te...</td>\n",
       "      <td>PLTR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NVIDIA Corporation</td>\n",
       "      <td>NVIDIA</td>\n",
       "      <td>https://www.investing.com/equities/nvidia-corp</td>\n",
       "      <td>NVDA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Apple Inc</td>\n",
       "      <td>Apple</td>\n",
       "      <td>https://www.investing.com/equities/apple-compu...</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Meta Platforms Inc</td>\n",
       "      <td>Meta Platforms</td>\n",
       "      <td>https://www.investing.com/equities/facebook-inc</td>\n",
       "      <td>META</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     company           stock  \\\n",
       "0                  Tesla Inc           Tesla   \n",
       "1  Palantir Technologies Inc        Palantir   \n",
       "2         NVIDIA Corporation          NVIDIA   \n",
       "3                  Apple Inc           Apple   \n",
       "4         Meta Platforms Inc  Meta Platforms   \n",
       "\n",
       "                                                link ticker  \n",
       "0    https://www.investing.com/equities/tesla-motors   TSLA  \n",
       "1  https://www.investing.com/equities/palantir-te...   PLTR  \n",
       "2     https://www.investing.com/equities/nvidia-corp   NVDA  \n",
       "3  https://www.investing.com/equities/apple-compu...   AAPL  \n",
       "4    https://www.investing.com/equities/facebook-inc   META  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../datasets/stocks.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "finished extracting news links\n"
     ]
    }
   ],
   "source": [
    "news_list_path = utils.create_path('../datasets/news_links')\n",
    "BASE_URL = 'https://www.investing.com'\n",
    "MAX_NUM_PAGES =20\n",
    "\n",
    "def extract_news_links(df, news_list_path,  max_num_pages=1):\n",
    "    for inx, (stock_name, stock_ticker, link) in enumerate(df[['stock', 'ticker', 'link']].values):\n",
    "        # if stock_ticker != 'TSLA':\n",
    "        #     continue\n",
    "        try:\n",
    "            with open(f'{news_list_path}/{stock_ticker}.txt', 'w') as file:\n",
    "                full_link = f'{link}-news'\n",
    "                for page in range(1, max_num_pages + 1):\n",
    "                    full_link = f'{link}-news/{page}'\n",
    "                    request = requests.get(full_link).text\n",
    "                    bs4 = BeautifulSoup(request, 'html.parser')\n",
    "                    news_table = bs4.find('ul', {'data-test': 'news-list'})\n",
    "                    news_list = news_table.find_all('article', {'data-test': 'article-item'})\n",
    "                    for news_data in news_list:\n",
    "                        if str(news_data).find('mt-2.5') == -1:\n",
    "                            news_link = news_data.findAll('a')[1]['href']\n",
    "                            full_link = f'{BASE_URL}{news_link}'\n",
    "                            file.write(f'{full_link}\\n')\n",
    "        except Exception as e:\n",
    "            print(f'Error for stock {stock_name}: {e}')\n",
    "if len(os.listdir(news_list_path)) == 0:\n",
    "    extract_news_links(df, news_list_path, max_num_pages=MAX_NUM_PAGES)\n",
    "# extract_news_links(df, news_list_path, max_num_pages=MAX_NUM_PAGES)\n",
    "print(\"finished extracting news links\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a dictionary of the links available from the files that created for each news' links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n"
     ]
    }
   ],
   "source": [
    "def create_dict_of_links(news_list_path):\n",
    "    news_dict = {}\n",
    "    for file_name in os.listdir(news_list_path):\n",
    "        # if file_name != 'TSLA.txt':\n",
    "        #     continue\n",
    "        with open(f'{news_list_path}/{file_name}', 'r') as file:\n",
    "            lines = file.readlines()\n",
    "            lines = list(set(lines))\n",
    "        stock_name = file_name.replace('.txt', '')\n",
    "        for line in lines:\n",
    "            if stock_name in news_dict:\n",
    "                news_dict[stock_name].append(line.replace('\\n', ''))\n",
    "            else:\n",
    "                news_dict[stock_name] = [line.replace('\\n', '')]\n",
    "    return news_dict\n",
    "news_dict = create_dict_of_links(news_list_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [02:54<00:00, 174.31s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def extract_news(news_dict):\n",
    "    df = pd.DataFrame(columns=['stock', 'title', 'text', 'date', 'time', 'am_pm'])\n",
    "    stock_list = []\n",
    "    title_list = []\n",
    "    date_list = []\n",
    "    time_list = []\n",
    "    am_pm_list = []\n",
    "    text_list = []\n",
    "    for inx, stock_name in enumerate(tqdm(news_dict)):\n",
    "        for link in news_dict[stock_name]:\n",
    "            stock_list.append(stock_name)\n",
    "            request = requests.get(link).text\n",
    "            bs4 = BeautifulSoup(request, 'html.parser')\n",
    "            # parsing the title of the article\n",
    "            try:\n",
    "                header = bs4.find('h1', {'id': 'articleTitle'}).text\n",
    "                title_list.append(header)\n",
    "            except Exception as e:\n",
    "                title_list.append(None)\n",
    "                print(f'Error in parsing \"\"Title(header)\"\" in stock: {stock_name} is: {e}')\n",
    "            # parsing the date and time of the article\n",
    "            try:\n",
    "                datetime = bs4.findAll('div', {'class': 'flex flex-row items-center'})[1].find('span').text\n",
    "                datetime = datetime.replace('Published ', '')[:]\n",
    "                datetime = dt.strptime(datetime, '%m/%d/%Y, %I:%M %p')\n",
    "                time = datetime.strftime('%H:%M')\n",
    "                date = datetime.strftime('%Y-%m-%d')\n",
    "                am_pm = datetime.strftime('%p')\n",
    "                date_list.append(date)\n",
    "                time_list.append(time)\n",
    "                am_pm_list.append(am_pm)\n",
    "            except Exception as e:\n",
    "                date_list.append(None)\n",
    "                time_list.append(None)\n",
    "                am_pm_list.append(None)\n",
    "                print(f'Error in parsing \"\"datetime\"\" in stock: {stock_name} is: {e}')\n",
    "                \n",
    "            try:\n",
    "                text = bs4.find('div', {'class': 'article_WYSIWYG__O0uhw article_articlePage__UMz3q text-[18px] leading-8'})\n",
    "                all_ps = text.findAll('p')\n",
    "                text = ''\n",
    "                for each_p in all_ps:\n",
    "                    text = text + each_p.text \n",
    "                    \n",
    "                if text == '':\n",
    "                    print(f'Error in parsing \"\"article body\"\" in stock: {stock_name} is: {e}')\n",
    "                \n",
    "                text = text.replace('Position added successfully to:', '')\n",
    "                text = text.replace('\\n', ' ')    \n",
    "                text_list.append(text) \n",
    "            except Exception as e:\n",
    "                print(f'Error in parsing \"\"article body\"\" in stock: {stock_name} is: {e}')\n",
    "                text_list.append(None)\n",
    "                \n",
    "    df['stock'], df['title'], df['text'] = stock_list, title_list, text_list\n",
    "    df['date'], df['time'], df['am_pm'] = date_list, time_list, am_pm_list   \n",
    "    return df\n",
    "df = extract_news(news_dict)\n",
    "df.to_csv('../datasets/stock_news.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4255, 6)\n",
      "(4255, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>am_pm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>Morning Bid: Dollar surges after central bank ...</td>\n",
       "      <td>A look at the day ahead in U.S. and global mar...</td>\n",
       "      <td>2024-03-22</td>\n",
       "      <td>06:08</td>\n",
       "      <td>AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>Evercore says Apple sell-off is overdone, sees...</td>\n",
       "      <td>Apple (NASDAQ:AAPL) stock remains one of the v...</td>\n",
       "      <td>2024-03-11</td>\n",
       "      <td>16:54</td>\n",
       "      <td>PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>US House passes bill to force ByteDance to div...</td>\n",
       "      <td>By David ShepardsonWASHINGTON (Reuters) -The U...</td>\n",
       "      <td>2024-03-13</td>\n",
       "      <td>06:01</td>\n",
       "      <td>AM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  stock                                              title  \\\n",
       "0  AAPL  Morning Bid: Dollar surges after central bank ...   \n",
       "1  AAPL  Evercore says Apple sell-off is overdone, sees...   \n",
       "2  AAPL  US House passes bill to force ByteDance to div...   \n",
       "\n",
       "                                                text        date   time am_pm  \n",
       "0  A look at the day ahead in U.S. and global mar...  2024-03-22  06:08    AM  \n",
       "1  Apple (NASDAQ:AAPL) stock remains one of the v...  2024-03-11  16:54    PM  \n",
       "2  By David ShepardsonWASHINGTON (Reuters) -The U...  2024-03-13  06:01    AM  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df = df.dropna(inplace=False)\n",
    "print(df.shape)\n",
    "df.to_csv('../datasets/stock_news.csv', index=False)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
