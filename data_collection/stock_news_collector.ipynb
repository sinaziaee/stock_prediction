{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sinaz\\AppData\\Local\\Temp\\ipykernel_25060\\2822559146.py:3: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import json\n",
    "import utils as utils\n",
    "from datetime import datetime as dt\n",
    "from newspaper import Article\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the Trending Stocks\n",
    "We will scrape investing.com for trending stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.investing.com/equities/trending-stocks'\n",
    "BASE_URL = 'https://www.investing.com'\n",
    "request = requests.get(url).text\n",
    "raw_text = BeautifulSoup(request, 'html.parser')\n",
    "trending_stocks = raw_text.find('div', {'id': 'trendingInnerContent'})\n",
    "stock_elements = trending_stocks.find_all('td', class_='left bold plusIconTd elp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the stock info including the company full name, stock name, and the link to the news page and other information of the stock in investing.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_stock_info(stock_elements):\n",
    "    stock_dict = {'company': [], 'stock': [], 'link': []}\n",
    "    for element in stock_elements:\n",
    "        company_name = element.find('a')['title']\n",
    "        company_name = company_name.replace('\\xa0', ' ')\n",
    "        stock_name = element.find('a').text\n",
    "        link = element.find('a')['href']\n",
    "        full_link = f'{BASE_URL}{link}'\n",
    "        stock_dict['company'].append(company_name)\n",
    "        stock_dict['stock'].append(stock_name)\n",
    "        stock_dict['link'].append(full_link)\n",
    "    df = pd.DataFrame(stock_dict)\n",
    "    return stock_dict, df\n",
    "stock_dict, df = extract_stock_info(stock_elements)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the constant json file named ticker.json to add the ticker name of the stocks in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ticker_names(json_path, df):\n",
    "    with open(json_path, 'r') as f:\n",
    "        stock_ticker_dict = json.load(f)\n",
    "\n",
    "    ticker_list = []\n",
    "    for stock_name in df['stock']:\n",
    "        if stock_name in stock_ticker_dict:\n",
    "            ticker_list.append(stock_ticker_dict[stock_name])\n",
    "        else:\n",
    "            print(f'{stock_name} not found in ticker list, you need to update the json file')\n",
    "    df['ticker'] = ticker_list\n",
    "    \n",
    "    utils.create_path('../datasets')\n",
    "    df.to_csv('../datasets/stocks.csv', index=False)\n",
    "    return df, stock_ticker_dict\n",
    "\n",
    "json_path = '../datasets/ticker.json'\n",
    "df, stock_ticker_dict = get_ticker_names(json_path, df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting the news links based on the stock name and saving them in a file with the name of the ticker.\n",
    "<br>\n",
    "You can change the number of pages to scrape more news articles. by default each page has 10 news. \n",
    "<br>\n",
    "Some of the news are tagged as pro and you need to subscribe to investing.com to get the articles. So we ignore them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>stock</th>\n",
       "      <th>link</th>\n",
       "      <th>ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tesla Inc</td>\n",
       "      <td>Tesla</td>\n",
       "      <td>https://www.investing.com/equities/tesla-motors</td>\n",
       "      <td>TSLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Apple Inc</td>\n",
       "      <td>Apple</td>\n",
       "      <td>https://www.investing.com/equities/apple-compu...</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Beyond Meat Inc</td>\n",
       "      <td>Beyond Meat</td>\n",
       "      <td>https://www.investing.com/equities/beyond-meat...</td>\n",
       "      <td>BYND</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Coinbase Global Inc</td>\n",
       "      <td>Coinbase Global</td>\n",
       "      <td>https://www.investing.com/equities/coinbase-gl...</td>\n",
       "      <td>COIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Salesforce Inc</td>\n",
       "      <td>Salesforce Inc</td>\n",
       "      <td>https://www.investing.com/equities/salesforce-com</td>\n",
       "      <td>CRM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               company            stock  \\\n",
       "0            Tesla Inc            Tesla   \n",
       "1            Apple Inc            Apple   \n",
       "2      Beyond Meat Inc      Beyond Meat   \n",
       "3  Coinbase Global Inc  Coinbase Global   \n",
       "4       Salesforce Inc   Salesforce Inc   \n",
       "\n",
       "                                                link ticker  \n",
       "0    https://www.investing.com/equities/tesla-motors   TSLA  \n",
       "1  https://www.investing.com/equities/apple-compu...   AAPL  \n",
       "2  https://www.investing.com/equities/beyond-meat...   BYND  \n",
       "3  https://www.investing.com/equities/coinbase-gl...   COIN  \n",
       "4  https://www.investing.com/equities/salesforce-com    CRM  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_list_path = utils.create_path('../datasets/news_links')\n",
    "def extract_news_links(stock_dict, news_list_path, stock_ticker_dict,  max_num_pages=1):\n",
    "    for inx, (stock_name, link) in enumerate(zip(stock_dict['stock'], stock_dict['link'])):\n",
    "        stock_ticker = stock_ticker_dict[stock_name]\n",
    "        try:\n",
    "            full_link = f'{link}-news'\n",
    "            for page in range(1, max_num_pages + 1):\n",
    "                full_link = f'{link}-news/{page}'\n",
    "                request = requests.get(full_link).text\n",
    "                bs4 = BeautifulSoup(request, 'html.parser')\n",
    "                news_table = bs4.find('ul', {'data-test': 'news-list'})\n",
    "                news_list = news_table.find_all('article', {'data-test': 'article-item'})\n",
    "                with open(f'{news_list_path}/{stock_ticker}.txt', 'w') as file:\n",
    "                    for news_data in news_list:\n",
    "                        if str(news_data).find('mt-2.5') == -1:\n",
    "                            news_link = news_data.findAll('a')[1]['href']\n",
    "                            full_link = f'{BASE_URL}{news_link}'\n",
    "                            file.write(f'{full_link}\\n')\n",
    "        except Exception as e:\n",
    "            print(f'Error for stock {stock_name}: {e}')\n",
    "extract_news_links(stock_dict, news_list_path, stock_ticker_dict, max_num_pages=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a dictionary of the links available from the files that created for each news' links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dict_of_links(news_list_path):\n",
    "    news_dict = {}\n",
    "    for file_name in os.listdir(news_list_path):\n",
    "        with open(f'{news_list_path}/{file_name}', 'r') as file:\n",
    "            lines = file.readlines()\n",
    "            lines = list(set(lines))\n",
    "        stock_name = file_name.replace('.txt', '')\n",
    "        for line in lines:\n",
    "            if stock_name in news_dict:\n",
    "                news_dict[stock_name].append(line.replace('\\n', ''))\n",
    "            else:\n",
    "                news_dict[stock_name] = [line.replace('\\n', '')]\n",
    "    return news_dict\n",
    "news_dict = create_dict_of_links(news_list_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_news(news_dict):\n",
    "    df = pd.DataFrame(columns=['stock', 'title', 'text', 'date', 'time', 'am_pm'])\n",
    "    stock_list = []\n",
    "    title_list = []\n",
    "    date_list = []\n",
    "    time_list = []\n",
    "    am_pm_list = []\n",
    "    text_list = []\n",
    "    for inx, stock_name in enumerate(news_dict):\n",
    "        if inx > 5:\n",
    "            break\n",
    "        for link in news_dict[stock_name]:\n",
    "            stock_list.append(stock_name)\n",
    "            request = requests.get(link).text\n",
    "            bs4 = BeautifulSoup(request, 'html.parser')\n",
    "            # parsing the title of the article\n",
    "            try:\n",
    "                header = bs4.find('h1', {'class': 'articleHeader'}).text\n",
    "                title_list.append(header)\n",
    "            except Exception as e:\n",
    "                title_list.append(None)\n",
    "                print(f'Error in parsing \"\"Title(header)\"\" in stock: {stock_name} is: {e}')\n",
    "            # parsing the date and time of the article\n",
    "            try:\n",
    "                datetime = bs4.findAll('div', {'class': 'contentSectionDetails'})[1].find('span').text\n",
    "                datetime = datetime.replace('Published ', '')[:-3]\n",
    "                datetime = dt.strptime(datetime, '%b %d, %Y %I:%M%p')\n",
    "                time = datetime.strftime('%H:%M')\n",
    "                date = datetime.strftime('%Y-%m-%d')\n",
    "                am_pm = datetime.strftime('%p')\n",
    "                date_list.append(date)\n",
    "                time_list.append(time)\n",
    "                am_pm_list.append(am_pm)\n",
    "            except Exception as e:\n",
    "                date_list.append(None)\n",
    "                time_list.append(None)\n",
    "                am_pm_list.append(None)\n",
    "                print(f'Error in parsing \"\"datetime\"\" in stock: {stock_name} is: {e}')\n",
    "                \n",
    "            try:\n",
    "                text = bs4.find('div', {'class': 'WYSIWYG articlePage'})\n",
    "                all_ps = text.findAll('p')\n",
    "                text = ''\n",
    "                for each_p in all_ps:\n",
    "                    text = text + each_p.text \n",
    "                    \n",
    "                if text == '':\n",
    "                    print(f'Error in parsing \"\"article body\"\" in stock: {stock_name} is: {e}')\n",
    "                \n",
    "                text = text.replace('Position added successfully to:', '')\n",
    "                text = text.replace('\\n', ' ')    \n",
    "                text_list.append(text) \n",
    "            except Exception as e:\n",
    "                print(f'Error in parsing \"\"article body\"\" in stock: {stock_name} is: {e}')\n",
    "                \n",
    "    df['stock'], df['title'], df['text'] = stock_list, title_list, text_list\n",
    "    df['date'], df['time'], df['am_pm'] = date_list, time_list, am_pm_list   \n",
    "    return df\n",
    "df = extract_news(news_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>am_pm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>BofA expects 'strong refresh cycle' for iPhone...</td>\n",
       "      <td>Citing findings from their global smartphone...</td>\n",
       "      <td>2024-02-28</td>\n",
       "      <td>07:49</td>\n",
       "      <td>AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>Apple cancels decade-long electric car project...</td>\n",
       "      <td>By Stephen Nellis and Shivansh Tiwary(Reuter...</td>\n",
       "      <td>2024-02-27</td>\n",
       "      <td>15:47</td>\n",
       "      <td>PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>Marketmind: Calm prevails before inflation dat...</td>\n",
       "      <td>A look at the day ahead in European an...</td>\n",
       "      <td>2024-02-28</td>\n",
       "      <td>00:41</td>\n",
       "      <td>AM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>Apple Halts Electric Car Project Titan, Shifts...</td>\n",
       "      <td>Quiver Quantitative - In a surprising ...</td>\n",
       "      <td>2024-02-27</td>\n",
       "      <td>15:44</td>\n",
       "      <td>PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>Marketmind: US tracking 3%+ growth; Apple down...</td>\n",
       "      <td>A look at the day ahead in U.S. and global...</td>\n",
       "      <td>2024-02-28</td>\n",
       "      <td>06:02</td>\n",
       "      <td>AM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  stock                                              title  \\\n",
       "0  AAPL  BofA expects 'strong refresh cycle' for iPhone...   \n",
       "1  AAPL  Apple cancels decade-long electric car project...   \n",
       "2  AAPL  Marketmind: Calm prevails before inflation dat...   \n",
       "3  AAPL  Apple Halts Electric Car Project Titan, Shifts...   \n",
       "4  AAPL  Marketmind: US tracking 3%+ growth; Apple down...   \n",
       "\n",
       "                                                text        date   time am_pm  \n",
       "0    Citing findings from their global smartphone...  2024-02-28  07:49    AM  \n",
       "1    By Stephen Nellis and Shivansh Tiwary(Reuter...  2024-02-27  15:47    PM  \n",
       "2          A look at the day ahead in European an...  2024-02-28  00:41    AM  \n",
       "3          Quiver Quantitative - In a surprising ...  2024-02-27  15:44    PM  \n",
       "4      A look at the day ahead in U.S. and global...  2024-02-28  06:02    AM  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../datasets/stock_news.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
